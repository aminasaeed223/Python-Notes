{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5b20470dbdd149dba0356582d662cc31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "Processing: ",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a1793b087e4828990e3ee6b3b267b7",
            "max": 84,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4af5d0ef2c014a45b142a84d10ff0bf8",
            "value": 84
          }
        },
        "e3a1793b087e4828990e3ee6b3b267b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af5d0ef2c014a45b142a84d10ff0bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dr-mushtaq/Python-Notes/blob/master/PyCaret_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">**Introduction**</p>"
      ],
      "metadata": {
        "id": "9d3sIjNFNkA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automated machine learning (AutoML) enables you to automate machine learning processes. There is a wide range of automation tools, created for different purposes. In general, machine learning tools are typically categorized into three categories of benefits—improving productivity, enforcing standardization, and promoting democratization.\n",
        "\n",
        "This article explains what is AutoML, key advantages of AutoML, and what you can actually automate in machine learning. Including a review of seven top AutoML tools [12]"
      ],
      "metadata": {
        "id": "q7AUygoDNsfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automated machine learning (AutoML) is the use of automation, machine learning, and best practices to make ML accessible to a wider range of users. It is designed to help organizations speed up their training and use of ML models despite limited or a lack of access to ML experts, such as data scientists.\n",
        "\n",
        "AutoML enables organizations to build and deploy models using templates, frameworks, and predefined processes. This speeds time to completion and helps ensure that models are as functional as possible[12]"
      ],
      "metadata": {
        "id": "xP4-8aHlN6Nq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages of AutoML**"
      ],
      "metadata": {
        "id": "fSzeHb64OJ_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three main advantages to incorporating AutoML. These are:\n",
        "\n",
        "- Productivity—automation reduces the manual resources needed to monitor and perform repetitive ML tasks. This frees teams to focus on model refinement and packaging.\n",
        "- Standardization—automated pipelines help reduce the chance of configuration errors and ensure that training and tests are performed uniformly.\n",
        "- Democratization—AutoML lowers the barrier to entry for organizations with little to no ML expertise. This increases competitiveness and can increase innovation."
      ],
      "metadata": {
        "id": "1Hya33KoQ-AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What Can We Automate in Machine Learning?**"
      ],
      "metadata": {
        "id": "lctIO_HjRH25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although it might be nice to fully automate ML processes, that is not what AutoML does. Rather, it focuses on a few areas with high repetition. These areas include the following."
      ],
      "metadata": {
        "id": "8c5eX3EZRMPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter optimization**\n",
        "\n",
        "Hyperparameters are values that define how a model is trained and directly impact the accuracy of training. For example, the rate of learning, number of hidden units or layers, activations functions, or the number of epochs.\n",
        "\n",
        "Hyperparameter optimization is a process of running your algorithm with different combinations of hyperparameters. This is done to determine which set produces the most accurate result. This process is performed with search algorithms, such as grid search, random search, or Bayesian methods.[12]"
      ],
      "metadata": {
        "id": "8WFkHnk4ROD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model selection**\n",
        "\n",
        "Model selection is a process of narrowing down candidate models for your training. It applies models to data to determine which model produces the optimum combination of performance, maintainability, and complexity. It is impacted by what resources are available to you and determines how your ML pipeline is structured.\n",
        "\n",
        "Model selection is automated similarly to hyperparameter optimization, by running through multiple models and comparing the results. It often involves the same sort of search methods as hyperparameter optimization as well. However, it may also include the use of more extensive filters, including Bayesian Information Criterion (BIC) or Akaike Information Criterion (AIC).[12]"
      ],
      "metadata": {
        "id": "44ZNgoSjRWj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature selection**\n",
        "\n",
        "Features are the data points used by your model to classify datasets. Feature selection involves defining how many features are going to be used, which features, and how defined those features are. The features you select directly impact the complexity of your model and its performance.\n",
        "\n",
        "Feature selection is automated through the application of algorithms during testing. For example, by using wrapper, filter, or embedded algorithms. During testing, features and combinations of features are evaluated to determine how accurate classifications or predictions are based on those features."
      ],
      "metadata": {
        "id": "5YjopMD_Rd7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top AutoML Tools**"
      ],
      "metadata": {
        "id": "JNCfzaPVRlJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run:AI** is a proprietary platform for automating machine learning infrastructure. In terms of AutoML the platform offers controls for automating resource management, as well as workload orchestration for your entire machine learning infrastructure.\n",
        "\n",
        "You can use Run:AI to pool GPU compute resources, set up GPU quotas, and continuously change resource allocation. These features enable you to actually optimize your compute resources, and ensure even highly intensive deep learning models consume resources at scale.[12]"
      ],
      "metadata": {
        "id": "JUH4y5dXRtUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. AutoKeras**\n",
        "\n",
        "AutoKeras is an open source library based on Keras that you can use for classification and regression of images, text, and structured data. It enables you to use pre-built blocks to construct a model, leaving you to focus on high-level architecture. AutoKeras supports use with Python 3.5 and up and TensorFlow 2.1.0 and up.[12]"
      ],
      "metadata": {
        "id": "K2XtOW87Xw5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Auto-WEKA**\n",
        "\n",
        "Auto-WEKA is an open source library that you can use to optimize your hyperparameter selection. It uses Bayesian optimization to select a learning algorithm and hyperparameters from those available in the WEKA package. Auto-WEKA has the same requirements as WEKA and includes a graphical user interface (GUI) for ease of use.[12]"
      ],
      "metadata": {
        "id": "qGUfbgPQX6-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. DataRobot Automated Machine Learning**\n",
        "\n",
        "DataRobot is a proprietary platform that you can use to automate and optimize model creation. It is designed for end-to-end support of model development, training, and deployment.\n",
        "\n",
        "DataRobot provides a range of features, including for data formatting, feature engineering, model selection, hyperparameter tuning, and monitoring. It also offers pretrained models, a data catalog, and a user friendly GUI with visualizations of the entire training and deployment process.[12]"
      ],
      "metadata": {
        "id": "n1y4nf9YYDj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. H20 AutoML**\n",
        "\n",
        "H2O is an open source platform for ML that is distributed and runs in-memory. It supports a wide range of ML and statistical algorithms, including deep learning, generalized linear models, and gradient boosted machines. While H2O is not automated, it includes a paid add-on, called H2O AutoML.\n",
        "\n",
        "H20 AutoML enables you to train and tune models with automatic feature selection and extraction, hyperparameter optimization, and use of ensembles (multiple models for greater performance). You can use H20 AutoML from a web GUI. It integrates with Hadoop, Spark, and Kubernetes."
      ],
      "metadata": {
        "id": "2zCAvYLRYPZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. MLBox**\n",
        "\n",
        "MLBox is an open source Python library that you can use to automate many aspects of model training. These aspects include data preprocessing, feature selection, and hyperparameter optimization. It also includes predictive models for regression and classification, such as LightGBM, Stacking, and Deep Learning."
      ],
      "metadata": {
        "id": "4fL8WAYLYU9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. auto-sklearn**\n",
        "\n",
        "auto-sklearn is an open source toolkit based on scikit-learn that you can use to perform model selection, feature engineering, and hyperparameter tuning. It includes features that enable you to leverage Bayesian optimization, ensembles, and meta-learning for more accurate models and training.\n",
        "\n",
        "When using auto-sklearn, you can restrict the time and memory limits of scikit-learn, restrict your searchspace, and control preprocessing. You also have the ability to inspect training statistics and results and perform parallel computations."
      ],
      "metadata": {
        "id": "PT4NnnAaYafT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1XA2lOe_hC"
      },
      "source": [
        "#<p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">**Table of Content**</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRvGGuOwfGui"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        " 1. Import Library\n",
        " 2. Installing Pycaret\n",
        " 3. Import necessary packages\n",
        " 4. Dataset\n",
        " 5. Classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2tTizNTf7o3"
      },
      "source": [
        "Data preprocessing is an integral step in Machine Learning as the quality of data and the useful information that can be derived from it directly affects the ability of our model to learn; therefore, it is extremely important that we preprocess our data before feeding it into our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ0HWWxbvs86"
      },
      "source": [
        "#<p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">**Import libaray**</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOHSx5sKvwti"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#from pycaret.utils import enable_colab\n",
        "#enable_colab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvDMiUrcxdQz"
      },
      "source": [
        "# **PyCaret**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQizT2BkkvfW"
      },
      "source": [
        "PyCaret is an open-source, low-code machine learning library and end-to-end model management tool built-in Python for automating machine learning workflows. It is incredibly popular for its ease of use, simplicity, and ability to build and deploy end-to-end ML prototypes quickly and efficiently.PyCaret is an alternate low-code library that can be used to replace hundreds of lines of code with few lines only. This makes the experiment cycle exponentially fast and efficient [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbPQUl3Tk-y3"
      },
      "source": [
        "PyCaret is simple and easy to use. All the operations performed in PyCaret are sequentially stored in a Pipeline that is fully automated for deployment. Whether it’s imputing missing values, one-hot-encoding, transforming categorical data, feature engineering, or even hyperparameter tuning, PyCaret automates all of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_JOM0_SsocA"
      },
      "source": [
        "PyCaret is an open-source, low-code machine learning library and end-to-end model management tool built-in Python for automating machine learning workflows. It is known for its ease of use, simplicity, and ability to quickly and efficiently build and deploy end-to-end ML prototypes.\n",
        "PyCaret is an alternate low-code library that can replace hundreds of code lines with few lines only. This makes the experiment cycle exponentially fast and efficient[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chq5x0vRtHVH"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1qj-WAAtNj7hDl6-o0Jg3gGS4jR1IaCGz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ-H819ny8GQ"
      },
      "source": [
        "#<p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">**Installing Pycaret**</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4d68BKRx1Tu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce90231-9631-4da2-bfd9-3952e8167240"
      },
      "source": [
        "#capture #suppresses the displays\n",
        "# install the full version\n",
        "!pip install pycaret[full]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycaret[full] in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (4.67.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.26.4)\n",
            "Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.1.4)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (3.1.6)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.11.4)\n",
            "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.4.2)\n",
            "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.0.3)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.13.0)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.7.0)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (4.5.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.32.3)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (8.6.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (3.1.1)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (3.5.0)\n",
            "Requirement already satisfied: matplotlib<3.8.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (3.7.5)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (5.24.1)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.2.1)\n",
            "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.15)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.10.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.14.4)\n",
            "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.26.0)\n",
            "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.1.3)\n",
            "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.0.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (3.1.1)\n",
            "Requirement already satisfied: shap~=0.44.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.44.1)\n",
            "Requirement already satisfied: interpret>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.6.9)\n",
            "Requirement already satisfied: umap-learn>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.5.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (6.0.2)\n",
            "Requirement already satisfied: ydata-profiling>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (4.15.0)\n",
            "Requirement already satisfied: explainerdashboard>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.4.8)\n",
            "Requirement already satisfied: fairlearn==0.7.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: kmodes>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.12.2)\n",
            "Requirement already satisfied: mlxtend>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.23.4)\n",
            "Requirement already satisfied: statsforecast<1.6.0,>=0.5.5 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.5.0)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.2.7)\n",
            "Requirement already satisfied: optuna>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (4.2.1)\n",
            "Requirement already satisfied: optuna-integration in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (4.2.1)\n",
            "Requirement already satisfied: scikit-optimize>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.10.2)\n",
            "Requirement already satisfied: mlflow>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.21.0)\n",
            "Requirement already satisfied: gradio>=3.50.2 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (5.22.0)\n",
            "Requirement already satisfied: boto3>=1.24.56 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.37.16)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.17.6 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.34.0)\n",
            "Requirement already satisfied: m2cgen>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.10.0)\n",
            "Requirement already satisfied: evidently~=0.4.16 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.4.40)\n",
            "Requirement already satisfied: dask>=2024.4.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2024.12.1)\n",
            "Requirement already satisfied: distributed>=2024.4.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2024.12.1)\n",
            "Requirement already satisfied: fugue~=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (0.8.7)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.3.3)\n",
            "Requirement already satisfied: Werkzeug<3.0,>=2.2 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.3.8)\n",
            "Requirement already satisfied: pytest<8.0.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (7.4.4)\n",
            "Requirement already satisfied: moto<5.0.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (4.2.14)\n",
            "Requirement already satisfied: dash[testing] in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn-intelex>=2023.0.1 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2025.2.0)\n",
            "Requirement already satisfied: catboost>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (1.2.7)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pycaret[full]) (2.1.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from sktime==0.26.0->pycaret[full]) (24.2)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.11/dist-packages (from sktime==0.26.0->pycaret[full]) (0.7.8)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.16 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.24.56->pycaret[full]) (1.37.16)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.24.56->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.24.56->pycaret[full]) (0.11.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost>=0.23.2->pycaret[full]) (0.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost>=0.23.2->pycaret[full]) (1.17.0)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders>=2.4.0->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.1->pycaret[full]) (8.1.8)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.1->pycaret[full]) (2024.10.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.1->pycaret[full]) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2024.4.1->pycaret[full]) (0.12.1)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.1->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.1->pycaret[full]) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.1->pycaret[full]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.1->pycaret[full]) (6.4.2)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.1->pycaret[full]) (1.26.20)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: nltk>=3.6.7 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (3.9.1)\n",
            "Requirement already satisfied: pydantic>=1.10.13 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (2.10.6)\n",
            "Requirement already satisfied: litestar>=2.8.3 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (2.15.1)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.9.0)\n",
            "Requirement already satisfied: watchdog>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (6.0.0)\n",
            "Requirement already satisfied: typer>=0.3 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.15.2)\n",
            "Requirement already satisfied: rich>=13 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (13.9.4)\n",
            "Requirement already satisfied: iterative-telemetry>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (0.0.10)\n",
            "Requirement already satisfied: dynaconf>=3.2.4 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (3.2.10)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (2025.1.31)\n",
            "Requirement already satisfied: ujson>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (5.10.0)\n",
            "Requirement already satisfied: uuid6>=2024.7.10 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (2024.7.10)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from evidently~=0.4.16->pycaret[full]) (43.0.3)\n",
            "Requirement already satisfied: dash-auth in /usr/local/lib/python3.11/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.3.0)\n",
            "Requirement already satisfied: dash-bootstrap-components>=1 in /usr/local/lib/python3.11/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: dtreeviz>=2.1 in /usr/local/lib/python3.11/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.2.2)\n",
            "Requirement already satisfied: flask_simplelogin in /usr/local/lib/python3.11/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: Flask-WTF>=1.1 in /usr/local/lib/python3.11/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.2.2)\n",
            "Requirement already satisfied: jupyter_dash>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.4.2)\n",
            "Requirement already satisfied: oyaml in /usr/local/lib/python3.11/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.11/dist-packages (from explainerdashboard>=0.3.8->pycaret[full]) (3.0.2)\n",
            "Requirement already satisfied: triad>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.9.8)\n",
            "Requirement already satisfied: adagio>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.2.6)\n",
            "Requirement already satisfied: qpd>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.4.4)\n",
            "Requirement already satisfied: fugue-sql-antlr>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fugue~=0.8.0->pycaret[full]) (0.2.2)\n",
            "Requirement already satisfied: sqlglot in /usr/local/lib/python3.11/dist-packages (from fugue~=0.8.0->pycaret[full]) (25.6.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (3.7.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.28.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (3.10.15)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (11.1.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.11.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.50.2->pycaret[full]) (4.12.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio>=3.50.2->pycaret[full]) (14.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt>=0.2.7->pycaret[full]) (0.10.9.7)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.0->pycaret[full]) (0.1.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.0->pycaret[full]) (3.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.12.0->pycaret[full]) (3.21.0)\n",
            "Requirement already satisfied: interpret-core==0.6.9 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (0.6.9)\n",
            "Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (6.17.1)\n",
            "Requirement already satisfied: SALib>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (1.5.1)\n",
            "Requirement already satisfied: dill>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (0.3.9)\n",
            "Requirement already satisfied: aplr>=10.6.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (10.8.0)\n",
            "Requirement already satisfied: dash-core-components>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: dash-html-components>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: dash-table>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (5.0.0)\n",
            "Requirement already satisfied: dash-cytoscape>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (1.0.2)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (24.11.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret[full]) (4.9.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret[full]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret[full]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret[full]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret[full]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8.0->pycaret[full]) (2.8.2)\n",
            "Requirement already satisfied: mlflow-skinny==2.21.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->pycaret[full]) (2.21.0)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->pycaret[full]) (1.15.1)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->pycaret[full]) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->pycaret[full]) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->pycaret[full]) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->pycaret[full]) (3.7)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->pycaret[full]) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow>=2.0.0->pycaret[full]) (2.0.39)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (5.5.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (0.46.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (3.1.44)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (1.31.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (4.25.6)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (0.5.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->pycaret[full]) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from flask->pycaret[full]) (1.9.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.11/dist-packages (from moto<5.0.0->pycaret[full]) (0.14.2)\n",
            "Requirement already satisfied: responses>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from moto<5.0.0->pycaret[full]) (0.25.7)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret[full]) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret[full]) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret[full]) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.55.0->pycaret[full]) (0.43.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.0.0->pycaret[full]) (6.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0->pycaret[full]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0->pycaret[full]) (2025.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.14.0->pycaret[full]) (9.0.0)\n",
            "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from plotly-resampler>=0.8.3.1->pycaret[full]) (0.1.4.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=2.0.4->pycaret[full]) (3.0.12)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<8.0.0->pycaret[full]) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest<8.0.0->pycaret[full]) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret[full]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret[full]) (3.10)\n",
            "Requirement already satisfied: daal==2025.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn-intelex>=2023.0.1->pycaret[full]) (2025.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from daal==2025.2.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (2022.0.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->daal==2025.2.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize>=0.9.0->pycaret[full]) (25.1.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.11/dist-packages (from shap~=0.44.0->pycaret[full]) (0.0.7)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.2->pycaret[full]) (0.5.13)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.17.6->pycaret[full]) (0.14.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost>=1.1.0->pycaret[full]) (2.21.5)\n",
            "Requirement already satisfied: visions<0.8.2,>=0.7.5 in /usr/local/lib/python3.11/dist-packages (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.3.1->pycaret[full]) (0.8.1)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.1.12)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.12.4)\n",
            "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.13.2)\n",
            "Requirement already satisfied: multimethod<2,>=1.4 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.12)\n",
            "Requirement already satisfied: typeguard<5,>=3 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.4.2)\n",
            "Requirement already satisfied: imagehash==4.3.1 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.3.1)\n",
            "Requirement already satisfied: wordcloud>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.9.4)\n",
            "Requirement already satisfied: dacite>=1.8 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.9.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from imagehash==4.3.1->ydata-profiling>=4.3.1->pycaret[full]) (1.8.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.6.0)\n",
            "Requirement already satisfied: stringcase>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.8.2 in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (4.13.3)\n",
            "Requirement already satisfied: lxml>=4.6.2 in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (5.3.1)\n",
            "Requirement already satisfied: percy>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (2.0.2)\n",
            "Requirement already satisfied: selenium<=4.2.0,>=3.141.0 in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (4.2.0)\n",
            "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (0.70.17)\n",
            "Requirement already satisfied: dash-testing-stub>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from dash[testing]; extra == \"full\"->pycaret[full]) (0.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow>=2.0.0->pycaret[full]) (1.3.9)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>=3.50.2->pycaret[full]) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.8.2->dash[testing]; extra == \"full\"->pycaret[full]) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (1.17.1)\n",
            "Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe,distributed]>=2023.5.0; extra == \"dask\"->fugue[dask]; extra == \"full\"->pycaret[full]) (1.1.21)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.11/dist-packages (from dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[full]) (0.1.5)\n",
            "Requirement already satisfied: wtforms in /usr/local/lib/python3.11/dist-packages (from Flask-WTF>=1.1->explainerdashboard>=0.3.8->pycaret[full]) (3.2.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime<4.12 in /usr/local/lib/python3.11/dist-packages (from fugue-sql-antlr>=0.1.6->fugue~=0.8.0->pycaret[full]) (4.11.1)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio>=3.50.2->pycaret[full]) (1.0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio>=3.50.2->pycaret[full]) (3.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (6.1.12)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (24.0.1)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.4.4)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.11/dist-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret[full]) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.23.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret[full]) (4.3.6)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.11/dist-packages (from jupyter_dash>=0.4.1->explainerdashboard>=0.3.8->pycaret[full]) (1.9.2)\n",
            "Requirement already satisfied: litestar-htmx>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (0.4.1)\n",
            "Requirement already satisfied: msgspec>=0.18.2 in /usr/local/lib/python3.11/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (0.19.0)\n",
            "Requirement already satisfied: multidict>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (6.1.0)\n",
            "Requirement already satisfied: multipart>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (1.2.1)\n",
            "Requirement already satisfied: polyfactory>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (2.19.0)\n",
            "Requirement already satisfied: rich-click in /usr/local/lib/python3.11/dist-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (1.8.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.6.7->evidently~=0.4.16->pycaret[full]) (2024.11.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret[full]) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13->evidently~=0.4.16->pycaret[full]) (3.0.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.0.0->pycaret[full]) (3.1.1)\n",
            "Requirement already satisfied: fs in /usr/local/lib/python3.11/dist-packages (from triad>=0.9.3->fugue~=0.8.0->pycaret[full]) (2.4.16)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.3->evidently~=0.4.16->pycaret[full]) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.9.0->evidently~=0.4.16->pycaret[full]) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.22.0->evidently~=0.4.16->pycaret[full]) (1.0.4)\n",
            "Requirement already satisfied: puremagic in /usr/local/lib/python3.11/dist-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.3.1->pycaret[full]) (1.28)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (6.5.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (2.22)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (2.38.0)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.11/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.11/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.9->interpret>=0.2.7->pycaret[full]) (7.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13->evidently~=0.4.16->pycaret[full]) (0.1.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (0.52b0)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (from polyfactory>=2.6.3->litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (37.0.2)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.3.0.post0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.2.0)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.11/dist-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (24.2.1)\n",
            "Requirement already satisfied: urllib3-secure-extra in /usr/local/lib/python3.11/dist-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (0.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[secure,socks]~=1.26->selenium<=4.2.0,>=3.141.0->dash[testing]; extra == \"full\"->pycaret[full]) (1.7.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (4.9)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.2.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.24.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow>=2.0.0->pycaret[full]) (0.6.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret[full]) (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwClIIrqnX-L",
        "outputId": "36869519-b866-458d-d654-ffebbd87e77f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyyaml==5.4.1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml==5.4.1 in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VKGDPlBlpaI"
      },
      "source": [
        "By installing the full version of pycaret, all the optional dependencies as listed here are also installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh4GSJw-1Y5a"
      },
      "source": [
        "#<p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">**Import the necessary packages**</p>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install markupsafe==2.0.1\n"
      ],
      "metadata": {
        "id": "RK3KHprB0smS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eccdc0e-c476-4206-dcf7-f5ef45c855ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting markupsafe==2.0.1\n",
            "  Downloading MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (31 kB)\n",
            "Installing collected packages: markupsafe\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 2.1.1\n",
            "    Uninstalling MarkupSafe-2.1.1:\n",
            "      Successfully uninstalled MarkupSafe-2.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-profiling 3.2.0 requires markupsafe~=2.1.1, but you have markupsafe 2.0.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed markupsafe-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runtime> Restart Runtime"
      ],
      "metadata": {
        "id": "6LPVVcETrlFq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ2lwtepnpJw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pycaret\n",
        "import jinja2\n",
        "#from pycaret.regression import*\n",
        "from pycaret.classification import*\n",
        "#pycaret.classification import *\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">**Dataset**</p>"
      ],
      "metadata": {
        "id": "7qKvhCCSXctf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.datasets import get_data\n",
        "all_datasets = get_data()"
      ],
      "metadata": {
        "id": "56uS89neX3Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.datasets import get_data\n",
        "dataset = get_data('iris')"
      ],
      "metadata": {
        "id": "ip2XVa5LX-rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "73719835-a780-4661-8754-471833e4dbdd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width      species\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d6ff4c5-830f-4f01-a4a4-e458a28ead5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d6ff4c5-830f-4f01-a4a4-e458a28ead5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d6ff4c5-830f-4f01-a4a4-e458a28ead5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d6ff4c5-830f-4f01-a4a4-e458a28ead5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd47c6f0-e483-4908-95f1-ec96885d4e19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd47c6f0-e483-4908-95f1-ec96885d4e19')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd47c6f0-e483-4908-95f1-ec96885d4e19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset = get_data('iris')\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2073644135332772,\n        \"min\": 4.6,\n        \"max\": 5.1,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.9,\n          5.0,\n          4.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2588435821108957,\n        \"min\": 3.0,\n        \"max\": 3.6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.0,\n          3.6,\n          3.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07071067811865474,\n        \"min\": 1.3,\n        \"max\": 1.5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.4,\n          1.3,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Iris-setosa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset.sample(frac=0.95, random_state=786).reset_index(drop=True)\n",
        "data_unseen = dataset.drop(data.index).reset_index(drop=True)\n",
        "\n",
        "print('Data for Modeling: ' + str(data.shape))\n",
        "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBnbw0uNMBbL",
        "outputId": "888d3e1e-d8d7-4ad5-fd9c-b5e3e47194ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for Modeling: (142, 5)\n",
            "Unseen Data For Predictions: (8, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">**Classification**</p>"
      ],
      "metadata": {
        "id": "mdmt3jUofJOb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmV8y9BlfDpF"
      },
      "source": [
        "\n",
        "##<p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">**Setting up Environment for Classification**</p>\n",
        "\n",
        "Common to all modules in PyCaret, the setup is the first and the only mandatory step in any machine learning experiment using PyCaret. This function takes care of all the data preparation required prior to training models. Besides performing some basic default processing tasks, PyCaret also offers a wide array of pre-processing features. To learn more about all the preprocessing functionalities in PyCaret, you can see this link. We use ‘pycaret.classification’ to set up with original dataset, target, and session_id. After we do it, we compare any models.\n",
        "\n",
        "setup function in PyCaret, profiles the dataset and infers the data types for all input features. It is the first and the only mandatory step to start any machine learning experiment in PyCaret."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiHZL2E-fpkr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "ae45b54c-7e86-476f-c7f6-f2bf354a16bf"
      },
      "source": [
        "from pycaret.classification import *\n",
        "exp_mclf101 = setup(data = dataset, target = 'species', session_id=123, experiment_name = 'diamond')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7da5d6ed7350>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_2659e_row9_col1 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_2659e\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_2659e_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
              "      <th id=\"T_2659e_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_2659e_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
              "      <td id=\"T_2659e_row0_col1\" class=\"data row0 col1\" >123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_2659e_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
              "      <td id=\"T_2659e_row1_col1\" class=\"data row1 col1\" >species</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_2659e_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
              "      <td id=\"T_2659e_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_2659e_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
              "      <td id=\"T_2659e_row3_col1\" class=\"data row3 col1\" >Iris-setosa: 0, Iris-versicolor: 1, Iris-virginica: 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_2659e_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
              "      <td id=\"T_2659e_row4_col1\" class=\"data row4 col1\" >(150, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_2659e_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
              "      <td id=\"T_2659e_row5_col1\" class=\"data row5 col1\" >(150, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_2659e_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
              "      <td id=\"T_2659e_row6_col1\" class=\"data row6 col1\" >(105, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_2659e_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
              "      <td id=\"T_2659e_row7_col1\" class=\"data row7 col1\" >(45, 5)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_2659e_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
              "      <td id=\"T_2659e_row8_col1\" class=\"data row8 col1\" >4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_2659e_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
              "      <td id=\"T_2659e_row9_col1\" class=\"data row9 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_2659e_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
              "      <td id=\"T_2659e_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_2659e_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
              "      <td id=\"T_2659e_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_2659e_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
              "      <td id=\"T_2659e_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_2659e_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
              "      <td id=\"T_2659e_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_2659e_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
              "      <td id=\"T_2659e_row14_col1\" class=\"data row14 col1\" >10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_2659e_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
              "      <td id=\"T_2659e_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_2659e_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
              "      <td id=\"T_2659e_row16_col1\" class=\"data row16 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_2659e_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
              "      <td id=\"T_2659e_row17_col1\" class=\"data row17 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_2659e_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
              "      <td id=\"T_2659e_row18_col1\" class=\"data row18 col1\" >diamond</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_2659e_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_2659e_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
              "      <td id=\"T_2659e_row19_col1\" class=\"data row19 col1\" >1ef9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpPVpLlEwC6w"
      },
      "source": [
        "When you initialize the setup function in PyCaret, it profiles the dataset and infers the data types for all input features. If all data types are correctly inferred, you can press enter to continue.[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovUHsgDmwJBO"
      },
      "source": [
        "Notice that:[4]\n",
        "\n",
        "- I have passed log_experiment = True and experiment_name = 'diamond' , this will tell PyCaret to automatically log all the metrics, hyperparameters, and model artifacts behind the scene as you progress through the modeling phase. This is possible due to integration with MLflow.\n",
        "\n",
        "- Also, I have used transform_target = True inside the setup. PyCaret will transform the Price variable behind the scene using box-cox transformation. It affects the distribution of data in a similar way as log transformation (technically different). If you would like to learn more about box-cox transformations, you can refer to this link."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1- Comparing All Models**"
      ],
      "metadata": {
        "id": "hZhwazLhr2Px"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vHop60ms9n7"
      },
      "source": [
        "This function trains all the available models in the model library using default hyperparameters and evaluates performance metrics using cross-validation. The number of folds can be defined using the foldparameter (default = 10 folds). The table is sorted (highest to lowest) by the metric of choice which can be defined using the sortparameter(in this case we have sorted it on RMSE)\n",
        "n_select parameter in the setup function controls the return of trained models. In this case, I am setting it to 15, meaning return the top 15 models as a list. pull function in the second line stores the output of compare_models as pd.DataFrame .\n",
        "\n",
        "Now that data is ready for modeling, let’s start the training process by using compare_models function. It will train all the algorithms available in the model library and evaluates multiple performance metrics using k-fold cross-validation.italicized text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZGSbzfZyG0s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586,
          "referenced_widgets": [
            "5b20470dbdd149dba0356582d662cc31",
            "e3a1793b087e4828990e3ee6b3b267b7",
            "4af5d0ef2c014a45b142a84d10ff0bf8"
          ]
        },
        "outputId": "6c7f9210-c80e-4b5c-e6a2-3a0212719144"
      },
      "source": [
        "compare_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "lda          Linear Discriminant Analysis    0.9809  0.9969  0.9833  0.9857   \n",
              "knn                K Neighbors Classifier    0.9800  0.9830  0.9806  0.9800   \n",
              "qda       Quadratic Discriminant Analysis    0.9709  0.9969  0.9750  0.9782   \n",
              "lr                    Logistic Regression    0.9609  0.9921  0.9611  0.9622   \n",
              "nb                            Naive Bayes    0.9609  0.9938  0.9611  0.9652   \n",
              "gbc          Gradient Boosting Classifier    0.9609  0.9782  0.9611  0.9723   \n",
              "dt               Decision Tree Classifier    0.9509  0.9616  0.9500  0.9598   \n",
              "et                 Extra Trees Classifier    0.9509  0.9890  0.9528  0.9532   \n",
              "rf               Random Forest Classifier    0.9409  0.9875  0.9417  0.9422   \n",
              "ada                  Ada Boost Classifier    0.9409  0.9895  0.9417  0.9467   \n",
              "xgboost         Extreme Gradient Boosting    0.9409  0.9824  0.9417  0.9422   \n",
              "lightgbm  Light Gradient Boosting Machine    0.9409  0.9883  0.9417  0.9422   \n",
              "catboost              CatBoost Classifier    0.9409  0.9907  0.9417  0.9422   \n",
              "ridge                    Ridge Classifier    0.8182  0.0000  0.8222  0.8304   \n",
              "svm                   SVM - Linear Kernel    0.7227  0.0000  0.7444  0.6062   \n",
              "dummy                    Dummy Classifier    0.3855  0.5000  0.3333  0.1489   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "lda       0.9809  0.9715  0.9739     0.013  \n",
              "knn       0.9800  0.9697  0.9697     0.138  \n",
              "qda       0.9709  0.9566  0.9602     0.013  \n",
              "lr        0.9596  0.9403  0.9422     0.766  \n",
              "nb        0.9605  0.9407  0.9432     0.023  \n",
              "gbc       0.9579  0.9402  0.9476     0.189  \n",
              "dt        0.9479  0.9249  0.9309     0.021  \n",
              "et        0.9509  0.9258  0.9269     0.409  \n",
              "rf        0.9396  0.9100  0.9119     0.457  \n",
              "ada       0.9391  0.9100  0.9146     0.084  \n",
              "xgboost   0.9396  0.9100  0.9119     0.325  \n",
              "lightgbm  0.9396  0.9100  0.9119     0.092  \n",
              "catboost  0.9396  0.9100  0.9119     0.667  \n",
              "ridge     0.8080  0.7251  0.7423     0.013  \n",
              "svm       0.6420  0.5863  0.6548     0.075  \n",
              "dummy     0.2147  0.0000  0.0000     0.013  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5c1a369-9ed5-4917-a38f-5a49ee53c90f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.9809</td>\n",
              "      <td>0.9969</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9809</td>\n",
              "      <td>0.9715</td>\n",
              "      <td>0.9739</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.9800</td>\n",
              "      <td>0.9830</td>\n",
              "      <td>0.9806</td>\n",
              "      <td>0.9800</td>\n",
              "      <td>0.9800</td>\n",
              "      <td>0.9697</td>\n",
              "      <td>0.9697</td>\n",
              "      <td>0.138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.9709</td>\n",
              "      <td>0.9969</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9782</td>\n",
              "      <td>0.9709</td>\n",
              "      <td>0.9566</td>\n",
              "      <td>0.9602</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.9609</td>\n",
              "      <td>0.9921</td>\n",
              "      <td>0.9611</td>\n",
              "      <td>0.9622</td>\n",
              "      <td>0.9596</td>\n",
              "      <td>0.9403</td>\n",
              "      <td>0.9422</td>\n",
              "      <td>0.766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.9609</td>\n",
              "      <td>0.9938</td>\n",
              "      <td>0.9611</td>\n",
              "      <td>0.9652</td>\n",
              "      <td>0.9605</td>\n",
              "      <td>0.9407</td>\n",
              "      <td>0.9432</td>\n",
              "      <td>0.023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.9609</td>\n",
              "      <td>0.9782</td>\n",
              "      <td>0.9611</td>\n",
              "      <td>0.9723</td>\n",
              "      <td>0.9579</td>\n",
              "      <td>0.9402</td>\n",
              "      <td>0.9476</td>\n",
              "      <td>0.189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.9509</td>\n",
              "      <td>0.9616</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.9598</td>\n",
              "      <td>0.9479</td>\n",
              "      <td>0.9249</td>\n",
              "      <td>0.9309</td>\n",
              "      <td>0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.9509</td>\n",
              "      <td>0.9890</td>\n",
              "      <td>0.9528</td>\n",
              "      <td>0.9532</td>\n",
              "      <td>0.9509</td>\n",
              "      <td>0.9258</td>\n",
              "      <td>0.9269</td>\n",
              "      <td>0.409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.9409</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.9417</td>\n",
              "      <td>0.9422</td>\n",
              "      <td>0.9396</td>\n",
              "      <td>0.9100</td>\n",
              "      <td>0.9119</td>\n",
              "      <td>0.457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.9409</td>\n",
              "      <td>0.9895</td>\n",
              "      <td>0.9417</td>\n",
              "      <td>0.9467</td>\n",
              "      <td>0.9391</td>\n",
              "      <td>0.9100</td>\n",
              "      <td>0.9146</td>\n",
              "      <td>0.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.9409</td>\n",
              "      <td>0.9824</td>\n",
              "      <td>0.9417</td>\n",
              "      <td>0.9422</td>\n",
              "      <td>0.9396</td>\n",
              "      <td>0.9100</td>\n",
              "      <td>0.9119</td>\n",
              "      <td>0.325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.9409</td>\n",
              "      <td>0.9883</td>\n",
              "      <td>0.9417</td>\n",
              "      <td>0.9422</td>\n",
              "      <td>0.9396</td>\n",
              "      <td>0.9100</td>\n",
              "      <td>0.9119</td>\n",
              "      <td>0.092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>catboost</th>\n",
              "      <td>CatBoost Classifier</td>\n",
              "      <td>0.9409</td>\n",
              "      <td>0.9907</td>\n",
              "      <td>0.9417</td>\n",
              "      <td>0.9422</td>\n",
              "      <td>0.9396</td>\n",
              "      <td>0.9100</td>\n",
              "      <td>0.9119</td>\n",
              "      <td>0.667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.8182</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8222</td>\n",
              "      <td>0.8304</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.7251</td>\n",
              "      <td>0.7423</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7227</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7444</td>\n",
              "      <td>0.6062</td>\n",
              "      <td>0.6420</td>\n",
              "      <td>0.5863</td>\n",
              "      <td>0.6548</td>\n",
              "      <td>0.075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Classifier</td>\n",
              "      <td>0.3855</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.1489</td>\n",
              "      <td>0.2147</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5c1a369-9ed5-4917-a38f-5a49ee53c90f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5c1a369-9ed5-4917-a38f-5a49ee53c90f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5c1a369-9ed5-4917-a38f-5a49ee53c90f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
              "                           solver='svd', store_covariance=False, tol=0.0001)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models(sort = 'Recall')"
      ],
      "metadata": {
        "id": "CspHA1YY2TEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models(fold = 5)"
      ],
      "metadata": {
        "id": "7e9zxxUe211z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2- Select Best Model**"
      ],
      "metadata": {
        "id": "OAhMkMv1r-pB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZfLqgVsuBXP"
      },
      "source": [
        "best= compare_models(n_select = 2, sort= 'Accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWV1Yz6Vx-oH"
      },
      "source": [
        "compare_model_result = pull()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CyvW0n6yt2U"
      },
      "source": [
        "since the RandomForestregressor was evaluated to have a comparatively better Accuracy, let us build the model using RandomForestregressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3- Create a Model**\n"
      ],
      "metadata": {
        "id": "3EUl9Lcn3R7H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTTkN03zAsnv"
      },
      "source": [
        "lda = create_model('lda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4- Tune a Model**"
      ],
      "metadata": {
        "id": "1ETq9k5vsKKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_dt = tune_model('lda')"
      ],
      "metadata": {
        "id": "BWqkQTC69Ps6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_lda= tune_model(lda, optimize='Accuracy', search_library='optuna')"
      ],
      "metadata": {
        "id": "fCxE2xRh9eFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5-Plot a Model**"
      ],
      "metadata": {
        "id": "vUp7JD9d9x7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.1- Analyze best model**"
      ],
      "metadata": {
        "id": "PPZm028O5FN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(lda)"
      ],
      "metadata": {
        "id": "Ht_cNwfy4vLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.2- Predict on new Data**"
      ],
      "metadata": {
        "id": "NAUhIb4K574X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions =predict_model(best,data=test);\n"
      ],
      "metadata": {
        "id": "0JpC6p2I6Rnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_predictions = predict_model(lda, data=data_unseen)\n",
        "unseen_predictions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "fHWeqFg8MMBo",
        "outputId": "5d418530-2c19-4a98-e7a6-9023d0870ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                          Model  Accuracy  AUC  Recall  Prec.  F1  Kappa  MCC\n",
              "0  Linear Discriminant Analysis         0    0       0      0   0      0    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dd13d90-811a-4eee-b87f-d14b5bfabbf3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dd13d90-811a-4eee-b87f-d14b5bfabbf3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8dd13d90-811a-4eee-b87f-d14b5bfabbf3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8dd13d90-811a-4eee-b87f-d14b5bfabbf3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width         species  \\\n",
              "0           5.8          2.7           5.1          1.9  Iris-virginica   \n",
              "1           6.8          3.2           5.9          2.3  Iris-virginica   \n",
              "2           6.7          3.3           5.7          2.5  Iris-virginica   \n",
              "3           6.7          3.0           5.2          2.3  Iris-virginica   \n",
              "4           6.3          2.5           5.0          1.9  Iris-virginica   \n",
              "\n",
              "            Label   Score  \n",
              "0  Iris-virginica  0.9980  \n",
              "1  Iris-virginica  1.0000  \n",
              "2  Iris-virginica  1.0000  \n",
              "3  Iris-virginica  0.9997  \n",
              "4  Iris-virginica  0.9888  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db1affb0-038b-4768-b543-1ac8014fedf9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>0.9980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.8</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5.9</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2.5</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>0.9997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>Iris-virginica</td>\n",
              "      <td>0.9888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db1affb0-038b-4768-b543-1ac8014fedf9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db1affb0-038b-4768-b543-1ac8014fedf9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db1affb0-038b-4768-b543-1ac8014fedf9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.3- Check the residuals of trained model**"
      ],
      "metadata": {
        "id": "KxzPcegptWzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'residuals_interactive')"
      ],
      "metadata": {
        "id": "DNG_IlN3tgOU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "e243c96c-f030-422a-8aaf-76b4144b4a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_381/1213786173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'residuals_interactive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pycaret/classification.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, use_train_data, verbose, display_format)\u001b[0m\n\u001b[1;32m   1695\u001b[0m         \u001b[0muse_train_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0msystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m         \u001b[0mdisplay_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m     )\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, feature_name, label, use_train_data, verbose, system, display, display_format, is_in_evaluate)\u001b[0m\n\u001b[1;32m   6084\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_available_plots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6085\u001b[0m         raise ValueError(\n\u001b[0;32m-> 6086\u001b[0;31m             \u001b[0;34m\"Plot Not Available. Please see docstring for list of available Plots.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6087\u001b[0m         )\n\u001b[1;32m   6088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Plot Not Available. Please see docstring for list of available Plots."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.4-Check feature importance**"
      ],
      "metadata": {
        "id": "qr31GBqNvFzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lda, plot = 'feature')"
      ],
      "metadata": {
        "id": "41PDE7NsugDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finalize the model\n",
        "final_best = finalize_model(lda)# save model to disk\n",
        "save_model(final_best, 'diamond-pipeline')"
      ],
      "metadata": {
        "id": "0hdS7dQIyZWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.5-Dashboard**"
      ],
      "metadata": {
        "id": "gFJM4kkuDvY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dashboard(lda, display_format='inline')"
      ],
      "metadata": {
        "id": "P5AUCzFYxPd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.6- ROC Curve**"
      ],
      "metadata": {
        "id": "oFlgqb9wtGCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we make it, let’s create charts for analyzing the model."
      ],
      "metadata": {
        "id": "MBba6kCmKS5c"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sydjGLFn2l9q"
      },
      "source": [
        "plot_model(tuned_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqovv2Qo2uAD"
      },
      "source": [
        "####**5.7-Interpret the results**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqx_HXzP2zfW"
      },
      "source": [
        "In PyCaret, we can interpret the model by SHAP values and correlation plot with just one line of code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGJ1m7LB21Kl"
      },
      "source": [
        "interpret_model(tuned_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.8-AUC Plot**"
      ],
      "metadata": {
        "id": "yWcwMLxoISnO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59PQJ7gD887c"
      },
      "source": [
        "plot_model(tuned_lda, plot = 'auc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.8-Precision-Recall Curve**"
      ],
      "metadata": {
        "id": "1v-qrZHHIocm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCQGhPFRBIIN"
      },
      "source": [
        "plot_model(tuned_lda, plot = 'pr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIFL9s6BCShq"
      },
      "source": [
        "####**5.9-Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrox--iDCUsq"
      },
      "source": [
        "plot_model(tuned_lda, plot = 'confusion_matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6-Cross-validation**"
      ],
      "metadata": {
        "id": "3v-EZ0PoJwoN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqKyteAU6p7s"
      },
      "source": [
        "**Cross-validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X4dVnJJ7Fnv"
      },
      "source": [
        "\n",
        "\n",
        "Evaluate the model on the holdout set used for validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGeJgsxK7Hd_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "a40cbddb-66f2-4c69-ba49-cf67eb9e0748"
      },
      "source": [
        "val_rf_pred = predict_model(tuned_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                          Model  Accuracy     AUC  Recall  Prec.      F1  \\\n",
              "0  Linear Discriminant Analysis    0.5692  0.5905     0.1   0.75  0.1765   \n",
              "\n",
              "    Kappa     MCC  \n",
              "0  0.0761  0.1482  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec5484a2-e732-4f17-9573-c98ff4250aa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.5692</td>\n",
              "      <td>0.5905</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.1765</td>\n",
              "      <td>0.0761</td>\n",
              "      <td>0.1482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec5484a2-e732-4f17-9573-c98ff4250aa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec5484a2-e732-4f17-9573-c98ff4250aa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec5484a2-e732-4f17-9573-c98ff4250aa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2jHuRce4ZyJ"
      },
      "source": [
        "The predictions (Label) made is as follows:-\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPpVAqui4dXa"
      },
      "source": [
        "val_rf_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHqgTlqP4u5_"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7- Make predictions on test data**"
      ],
      "metadata": {
        "id": "yX0mFC1Kt41j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are almost done! We finalize the model and predict it with the original dataset. Let’s read the final dataset. As we can see, it has added labels and scores."
      ],
      "metadata": {
        "id": "OtyC7sc1M8c6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NLEEGb04mXt"
      },
      "source": [
        "# predictions on new datasetRESULT_TEXT\n",
        "pred_new_rf = predict_model(tuned_rf, data = X_test) #new_data is pd dataframe\n",
        "#pred_new_rf = pred_new_rf.rename(columns={‘RESULT_TEXT’:’prediction’})\n",
        "pred_new_rf = pred_new_rf.rename(columns={'RESULT_TEXT':'Prediction'})\n",
        "pred_new_rf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_final = finalize_model(rf)\n",
        "predict_rf = predict_model(rf_final,data)\n",
        "\n",
        "predict_rf.head()"
      ],
      "metadata": {
        "id": "ju5COIRoNAOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6gWngOp5nVV"
      },
      "source": [
        "RandomForestRegressor submission Scores(RMSE) : 4234.403588306586.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9- Finalize and Save Pipeline**"
      ],
      "metadata": {
        "id": "SB6bb_FAuCny"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdn3dsRUEpgV"
      },
      "source": [
        "**Finalize and Save Pipeline**\n",
        "\n",
        "Let’s now finalize the best model i.e. train the best model on the entire dataset including the test set and then save the pipeline as a pickle file.\n",
        "\n",
        "Caution: One final word of caution. Once the model is finalized using finalize_model(), the entire dataset including the test/hold-out set is used for training. As such, if the model is used for predictions on the hold-out set after finalize_model() is used, the information grid printed will be misleading as you are trying to predict on the same data that was used for modeling. In order to demonstrate this point only, we will use final_rf under predict_model() to compare the information grid with the one above in section 11\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlF9n42bEsLY"
      },
      "source": [
        "# finalize the model\n",
        "final_best = finalize_model(lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6NFnz7vFUXP"
      },
      "source": [
        "# save model to disk\n",
        "save_model(final_best, 'diamond-pipeline')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAvAJItdFe13"
      },
      "source": [
        "save_model function will save the entire pipeline (including the model) as a pickle file on your local disk. By default, it will save the file in the same folder as your Notebook or script is in but you can pass the complete path as well if you would like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzC0_ZK7FoxU"
      },
      "source": [
        "save_model(final_best, 'E:/Major Revision/finarf'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_model(final_best);"
      ],
      "metadata": {
        "id": "QZEDn6CXLLUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loading the saved model**"
      ],
      "metadata": {
        "id": "50HWSabbVtcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_final_rf = load_model('Final RF Model 08Feb2020')"
      ],
      "metadata": {
        "id": "4D2iRcy7V6qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQgWLzcm4s3i"
      },
      "source": [
        "## **Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOAzkBRN50XG"
      },
      "source": [
        "**Model Training & Selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mvTuTmv5n16"
      },
      "source": [
        "from pycaret.regression import *\n",
        "s = setup(MiceImputed, target = 'RESULT_TEXT', transform_target = True, log_experiment = True, experiment_name = 'diamond')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZhVEC_V5-6D"
      },
      "source": [
        "compare_models()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVcEsi-46IHU"
      },
      "source": [
        "**Select Best Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaC_BlJo6Kq-"
      },
      "source": [
        "best= compare_models(n_select = 2, sort= 'RMSE')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG82tHJ464jf"
      },
      "source": [
        "### **Building Ensemble Models using PyCaret**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOmJHj0E5wNf"
      },
      "source": [
        "Ensemble models in machine learning combine the decisions from multiple models to improve the overall performance. In PyCaret, we can create bagging, boosting, blending, and stacking ensemble models with just one line of code. Here we will try with blending.\n",
        "Blending models is a method of ensembling which uses consensus among estimators to generate final predictions. The idea behind blending is to combine different machine learning algorithms and use a majority vote or the average predicted probabilities in case of classification to predict the final outcome."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bagged_dt = ensemble_model(dt, method = 'Bagging')"
      ],
      "metadata": {
        "id": "ykv0j3HS5Ju5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXVYs8LA9tnG"
      },
      "source": [
        "# train a voting regressor dynamically\n",
        "blender_specific = blend_models(estimator_list = compare_models(n_select = 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q67_AV2v6G_k"
      },
      "source": [
        "The calibrated blending model is as follows:-\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj8GY31cd_ie"
      },
      "source": [
        "blender_specific"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtPrJpWDeJJD"
      },
      "source": [
        "**Analyzing model performance in PyCaret**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HNLexbneNx2"
      },
      "source": [
        "plot_model(blender_specific)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI2a_yYOgk2s"
      },
      "source": [
        "**Evaluate the model performance**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kcPnISignRz"
      },
      "source": [
        "evaluate_model(blender_specific)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Vb0BLfg1Wc"
      },
      "source": [
        "**Make predictions on the validation set**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnlApCWHg30U"
      },
      "source": [
        "val_pred = predict_model(blender_specific)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I644BH0ghBGE"
      },
      "source": [
        "**Make Predictions on unseen data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl5vGADphDja"
      },
      "source": [
        "# predictions on new dataset\n",
        "pred_new = predict_model(blender_specific, data = X_train) #new_data is pd dataframe\n",
        "pred_new = pred_new.rename(columns={‘RESULT_VALUE’:'prediction'})\n",
        "pred_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx_ALQazhrLc"
      },
      "source": [
        "**Save and Load the Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R7TJ9PPhuPD"
      },
      "source": [
        "save_model(blender_specific , ‘/content/drive/MyDrive/blender_specific_saved_06142021’)\n",
        "# Loading the saved model\n",
        "blend_saved = load_model(‘/content/drive/MyDrive/blender_specific_saved_06142021’)\n",
        "pred = blend_saved.predict(test)\n",
        "pred[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clustering**"
      ],
      "metadata": {
        "id": "M_3HqZgVywDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset**"
      ],
      "metadata": {
        "id": "ljJJ_o0ek8r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.datasets import get_data\n",
        "data = get_data('mice')"
      ],
      "metadata": {
        "id": "LhrR3H_wlJn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset.sample(frac=0.95, random_state=786)\n",
        "data_unseen = dataset.drop(data.index)"
      ],
      "metadata": {
        "id": "hUakoch1vzS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.reset_index(drop=True, inplace=True)\n",
        "data_unseen.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Lilw4l-Dv42X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting up Environment in PyCaret**"
      ],
      "metadata": {
        "id": "ieFEDaBLmY8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.clustering import *\n",
        "exp_clu101 = setup(data, normalize = True,\n",
        "                   ignore_features = ['MouseID'],\n",
        "                   session_id = 123)"
      ],
      "metadata": {
        "id": "zpFB9y0DmhZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The setup function in PyCaret initializes the environment and creates the transformation pipeline for modeling and deployment. setup must be called before executing any other function in pycaret. It takes only one mandatory parameter: a pandas dataframe. All other parameters are optional can be used to customize the preprocessing pipeline[15]"
      ],
      "metadata": {
        "id": "KpBTJ9mlm6H8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When setup is executed, PyCaret's inference algorithm will automatically infer the data types for all features based on certain properties. The data type should be inferred correctly but this is not always the case. To handle this, PyCaret displays a prompt, asking for data types confirmation, once you execute the setup. You can press enter if all data types are correct or type quit to exit the setup[14]"
      ],
      "metadata": {
        "id": "GfWAjS-SnDy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuring that the data types are correct is really important in PyCaret as it automatically performs multiple type-specific preprocessing tasks which are imperative for machine learning models[15]"
      ],
      "metadata": {
        "id": "pQuFPPZonJrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can also use numeric_features and categorical_features parameters in the setup to pre-define the data types."
      ],
      "metadata": {
        "id": "sfKYOrbznQBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the setup has been successfully executed it displays the information grid which contains some important information about the experiment. Most of the information is related to the pre-processing pipeline which is constructed when setup is executed. The majority of these features are out of scope for this tutorial, however, a few important things to note are [15]"
      ],
      "metadata": {
        "id": "2m4xTwCUnZt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**session_id:** A pseduo-random number distributed as a seed in all functions for later reproducibility. If no session_id is passed, a random number is automatically generated that is distributed to all functions. In this experiment, the session_id is set as 123 for later reproducibility."
      ],
      "metadata": {
        "id": "r57In012pljq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing Values:** When there are missing values in original data this will show as True. Notice that Missing Values in the information grid above is Trueas the data contains missing values which are automatically imputed using mean for the numeric features and constant for the categorical features in the dataset. The method of imputation can be changed using the numeric_imputation and categorical_imputation parameters in the setup"
      ],
      "metadata": {
        "id": "LyQmgddAptG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original Data:** Displays the original shape of the dataset. In this experiment (1026, 82) means 1026 samples and 82 features."
      ],
      "metadata": {
        "id": "MTYtou8Ep2Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformed Data:** Displays the shape of the transformed dataset. Notice that the shape of the original dataset (1026, 82) is transformed into (1026, 91). The number of features has increased due to the encoding of categorical features in the dataset."
      ],
      "metadata": {
        "id": "ZckK5PEep4hZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Numeric Features:** The number of features inferred as numeric. In this dataset, 77 out of 82 features are inferred as numeric."
      ],
      "metadata": {
        "id": "yu4BpHTkqEa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical Features:** The number of features inferred as categorical. In this dataset, 5 out of 82 features are inferred as categorical. Also notice that we have ignored one categorical feature MouseID using the ignore_feature parameter since it's a unique identifier for each sample and we don’t want it to be considered during model training."
      ],
      "metadata": {
        "id": "wdUZ7nj3qLHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how a few tasks that are imperative to perform modeling are automatically handled such as missing value imputation, categorical encoding, etc. Most of the parameters in the setup function are optional and used for customizing the pre-processing pipeline. These parameters are out of scope for this tutorial but I will write more about them later."
      ],
      "metadata": {
        "id": "GvUL7h3EqNZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create a Model**"
      ],
      "metadata": {
        "id": "xU3lqtcP2q-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a clustering model in PyCaret is simple and similar to how you would create a model in the supervised learning modules of PyCaret. A clustering model is created using the create_model function. This function returns a trained model object and a few unsupervised metrics. See an example below:"
      ],
      "metadata": {
        "id": "f5ZLHVx4qZE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = create_model('kmeans')"
      ],
      "metadata": {
        "id": "Yti4gJHxqet3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(kmeans)\n"
      ],
      "metadata": {
        "id": "TUkJGParqkkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have trained an unsupervised K-Means model using the create_model. Notice the n_clusters parameter is set to 4 which is the default when you do not pass a value to the num_clusters parameter. In the below example we will create a kmodes model with 6 clusters."
      ],
      "metadata": {
        "id": "wiyPQxggqv_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmodes = create_model('kmodes', num_clusters = 6)"
      ],
      "metadata": {
        "id": "aFbyd_sLq1UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the complete list of models available in the model library, please check the documentation or use the models function."
      ],
      "metadata": {
        "id": "HnRfXWT7q_pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models()"
      ],
      "metadata": {
        "id": "GFZy4Rp-rC9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Assign a Model**"
      ],
      "metadata": {
        "id": "xkmlue6DrMta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have trained a model, we can assign the cluster labels to our training dataset (1026 samples) by using the assign_model function."
      ],
      "metadata": {
        "id": "kXkWu16brSdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmean_results = assign_model(kmeans)\n",
        "kmean_results.head()"
      ],
      "metadata": {
        "id": "S8kkCZARrYjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that a new column called Cluster has been added to the original dataset.\n",
        "Note that the results also include the MouseID column that we actually dropped during the setup. Don’t worry, it is not used for the model training, rather is only appended to the dataset only when assign_model is called."
      ],
      "metadata": {
        "id": "rsnpWIdhri81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plot a Model**"
      ],
      "metadata": {
        "id": "4_9A4ZBarozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot_model function is used to analyze clustering models. This function takes a trained model object and returns a plot."
      ],
      "metadata": {
        "id": "NmFvwJTBrw4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cluster PCA Plot**"
      ],
      "metadata": {
        "id": "Akt4BdDsrz6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(kmeans)"
      ],
      "metadata": {
        "id": "4SV8fl5DrtzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cluster labels are automatically colored and shown in a legend. When you hover over the data points you will see additional features which by default use the first column of the dataset (in this case MouseID). You can change this by passing the feature parameter and you may also set label to True if you want labels to be printed on the plot."
      ],
      "metadata": {
        "id": "Wp-hSDOjsAma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(kmeans, plot = 'cluster')\n"
      ],
      "metadata": {
        "id": "hNfRlLjhs8It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elbow Plot**"
      ],
      "metadata": {
        "id": "KUKg2IQRuBmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(kmeans, plot = 'elbow')"
      ],
      "metadata": {
        "id": "BIVdUiH_sQVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(kmeans, plot= 'elbow')\n"
      ],
      "metadata": {
        "id": "CrL9u4UpuZiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Evaulation**"
      ],
      "metadata": {
        "id": "OYZqAuk1tOkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(kmeans)"
      ],
      "metadata": {
        "id": "QxsPXOMvtWIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predict on unseen data**"
      ],
      "metadata": {
        "id": "f_8DGVPwvaEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predict_model function is used to assign cluster labels to a new unseen dataset. We will now use our trained kmeans model to predict the data stored in data_unseen. This variable was created at the beginning of the tutorial and contains 54 samples from the original dataset that were never exposed to PyCaret."
      ],
      "metadata": {
        "id": "en5_DHkNvegP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_predictions = predict_model(kmeans, data=data_unseen)\n",
        "unseen_predictions.head()"
      ],
      "metadata": {
        "id": "_eTuUOfkvinP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Saving the model**"
      ],
      "metadata": {
        "id": "5zok3w4JwGtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have now finished the experiment by using our kmeans model to predict labels on unseen data.\n",
        "This brings us to the end of our experiment, but one question is still to be asked: What happens when you have more new data to predict? Do you have to go through the entire experiment again? The answer is no, PyCaret’s inbuilt function save_model allows you to save the model along with the entire transformation pipeline for later use."
      ],
      "metadata": {
        "id": "IuwgcAiDwKt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(kmeans,’Final KMeans Model 25Nov2020')"
      ],
      "metadata": {
        "id": "r-5Eewe3wPTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(lr, 'saved_kmeans_model')"
      ],
      "metadata": {
        "id": "s0frrcRxwrZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Method 2**"
      ],
      "metadata": {
        "id": "zOSmWAx7wX-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.clustering import *"
      ],
      "metadata": {
        "id": "NSHT2vZty-G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_clusters(Train_data, model = 'kmodes', num_clusters = 3)"
      ],
      "metadata": {
        "id": "-f8QOXrizFVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "kvNdCcTUzXoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Anomaly Detection**"
      ],
      "metadata": {
        "id": "7mPw1xdUZ5q5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anomaly Detection is a machine learning technique used for identifying rare items, events, or observations by checking for rows in the table that differ significantly from the majority of the rows. Typically, the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problem or error. Some common business use cases for anomaly detection are:\n",
        "✔ Fraud detection (credit cards, insurance, etc.) using financial data.\n",
        "✔ Intrusion detection (system security, malware) or monitoring for network traffic surges and drops.\n",
        "✔ Identifying multivariate outliers in the dataset.\n",
        "[13]"
      ],
      "metadata": {
        "id": "onFY8NGpaH8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Datasets/Anomaly Detection/anomaly.csv\")"
      ],
      "metadata": {
        "id": "pPXT8o46alkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Creation**"
      ],
      "metadata": {
        "id": "k_fwgDyZstcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose the optimal model from the model library and create models for anomaly detection. We can display the list of models by using the model() function.[14]"
      ],
      "metadata": {
        "id": "VfySs8gRsx3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.anomaly import *\n",
        "setup = setup(df, session_id = 123)"
      ],
      "metadata": {
        "id": "nxbaHfv-sTDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify the session id, this results in processing after execution. It interprets numerous types of variables automatically and allows us to confirm by pressing ENTER to continue.\n",
        "\n",
        "Observe that our dataset consists of 10 features, 1000 rows each. We can perform various imputations- numeric and categorical or normalize the data. But we don’t require such transformations in our dataset so let us continue!\n",
        "\n",
        "Performing all these computations with a few lines of code presents the beauty of the PyCaret library[14]"
      ],
      "metadata": {
        "id": "ZOIsZIRcsfvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models()"
      ],
      "metadata": {
        "id": "JpcF70ljs5iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scikit-learn==0.23.2"
      ],
      "metadata": {
        "id": "CH6ui8UebHMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.anomaly import *\n",
        "dataset = get_outliers(data = data)"
      ],
      "metadata": {
        "id": "175xmGqSa4V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "tIYDC1pMbrsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two new columns are attached to the original table. Label (1 = outlier, 0 = inlier) and Score (data points with high scores are categorized as outlier)."
      ],
      "metadata": {
        "id": "DLMGPIbBb9D8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, PyCaret trains a K-Nearest Neighbors Anomaly Detector with 5% fraction (i.e. 5% of the total number of rows in the table will be flagged as outlier). Default values can be changed easily:\n",
        "\n",
        "To change the fraction value you can use fraction parameter within get_outliers( ) function.\n",
        "To change model type use model parameter within get_outliers( ).\n",
        "See the following code for training an Isolation Forest model with 0.1 fraction:[13]"
      ],
      "metadata": {
        "id": "cWHGemcKcLli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.anomaly import *\n",
        "dataset = get_outliers(dataset, model = 'iforest', fraction = 0.1)"
      ],
      "metadata": {
        "id": "tmdQ539fcVLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "E9iaXbxqcYhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are over 10 ready-to-use anomaly detection algorithms in PyCaret:"
      ],
      "metadata": {
        "id": "FyWrwFjZcpbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=11lZ2xTuK4X7u5NlMxQ23hZgTo53pDZ1D)"
      ],
      "metadata": {
        "id": "5LGdIYxDn5Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the preprocessing tasks necessary to train an anomaly detection model such as missing value imputation (if table has any missing or null values), or normalization, or one-hot-encoding, they all are automatically performed before training an anomaly detection model. Click here to learn more about PyCaret’s preprocessing capabilities.\n",
        "\n",
        "💡 In this example we have used the **get_outliers( )** function to assign outlier label and score for analysis. Every time the query is refreshed, outliers are recalculated. An alternate way to implement this would be to use the predict_model( ) function to predict outliers using a pre-trained model in Python [13]"
      ],
      "metadata": {
        "id": "LJdK2lQdc52L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Isolation Forest**"
      ],
      "metadata": {
        "id": "nputVV5uuDc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the isolation Forest model by using the create_model() function. The isolation Forest algorithm differentiates observations by randomly selecting a feature and then randomly selecting split values between the maximum and minimum values.[14]"
      ],
      "metadata": {
        "id": "-euFWPe0uIFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iforest = create_model('iforest')\n",
        "print(iforest)"
      ],
      "metadata": {
        "id": "2kUAATYQuSKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus an anomaly score is determined as the number of conditions required to separate given observations.\n",
        "\n"
      ],
      "metadata": {
        "id": "Dim2QHE8ueFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Local Outlier Factor**\n"
      ],
      "metadata": {
        "id": "Jq_OmS0Ruktc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is an algorithm of the unsupervised anomaly detection method and computes the local density deviation of a data point with respect to its neighbor"
      ],
      "metadata": {
        "id": "Ezb8n0l1upt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lof = create_model('lof')\n",
        "print(lof)"
      ],
      "metadata": {
        "id": "3mSZZ1BiuuhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **K Nearest Neighbors**\n"
      ],
      "metadata": {
        "id": "b2jJtdaSvKF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN is a non-parametric lazy learning algorithm used to classify data based on similarities and various distance metrics. It provides a simple yet firm approach to detecting anomalies"
      ],
      "metadata": {
        "id": "WdILErhevO19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = create_model('knn')\n"
      ],
      "metadata": {
        "id": "pzFpCCthvU4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Comparing anomalies in models**"
      ],
      "metadata": {
        "id": "P0zLF7Plvb3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving on with our task we can now observe the anomalies determined by the models. Traditionally, we have to manually set up different parameters.\n",
        "\n",
        "But with the use of PyCaret, we can just assign results via the assigned model function. We’ll start with the isolation forest model.[14]"
      ],
      "metadata": {
        "id": "Imwlvluhvgz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iforest_results = assign_model(iforest)\n",
        "iforest_results.head()"
      ],
      "metadata": {
        "id": "3k-gQQOnvtrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "assign_model() function returns a data frame with detection of anomalies, the presence of outliers are marked as 1 and non-outliers as 0, along with anomaly scores."
      ],
      "metadata": {
        "id": "WVM1-1Sjv56N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter the anomalies by each model, this shows that there are 50 rows out of 1000 considered as anomalies by iforest model."
      ],
      "metadata": {
        "id": "2OCdhiY0wJ0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iforest_anomaly=iforest_results[iforest_results['Anomaly']==1]\n",
        "iforest_anomaly.shape"
      ],
      "metadata": {
        "id": "zoSDoyVswNlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lof_anomaly=lof_results[lof_results['Anomaly']==1]\n",
        "lof_anomaly.shape"
      ],
      "metadata": {
        "id": "Kr-gF8zkxoyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_anomaly=knn_results[knn_results['Anomaly']==1]\n",
        "knn_anomaly.shape"
      ],
      "metadata": {
        "id": "t3TwBSW9xt4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Interpretation and visualization**\n"
      ],
      "metadata": {
        "id": "ghn94YjKx3Ph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization is the most convenient way to interpret the information at hand in a creative and independent manner.\n",
        "\n",
        "Let us start by creating visuals from outside the PyCaret library which will highlight the benefits of the PyCaret library and enable us to understand how the plot_model function is much more interactive.[14]"
      ],
      "metadata": {
        "id": "BmEaF8rtx-YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.features import Manifold\n",
        "dfr = iforest_results['Anomaly']\n",
        "viz = Manifold(manifold=\"tsne\")\n",
        "viz.fit_transform(df, dfr)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "exkK6bTCyD56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see most of the anomalies determined by the isolation forest in multiple dimensions are usually out of different clusters.\n",
        "\n",
        "Now use the plot_model() function for KNN within PyCaret that will create a 3D plot for outliers, in which we can see why certain features are considered as an anomaly."
      ],
      "metadata": {
        "id": "_7ICl522yKQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(knn)"
      ],
      "metadata": {
        "id": "RkPucs0CyOV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can move it in any dimension to see and point out the anomalies. This 3D plot helps us to view it better. The KNN plot shows that most of the outliers are those which were not part of any clusters. So that’s good to go!\n",
        "\n",
        "The same can be done for the other two models."
      ],
      "metadata": {
        "id": "VmKNwUTxya6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(iforest)"
      ],
      "metadata": {
        "id": "b53dVh2uymKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clearly visible that the data set is divided into four different clusters, So anything out of these groups will surely be an anomaly.\n",
        "\n",
        "Anomalies are not always a bad sign! Sometimes they can be very useful in interpreting results or data analysis. These can be used to solve distinct data science usecases.\n",
        "\n",
        "Moving on to the third model ie. linear outlier factor we can experiment with a different plot that creates a 2D plot."
      ],
      "metadata": {
        "id": "063hjjNmysOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can zoom this 2D plot to view which points were considered as outliers.\n",
        "\n",
        "Another visual can be created for pair plot again, now with the anomalies\n",
        "to see which points will count as anomalies."
      ],
      "metadata": {
        "id": "7h0PGRc5ywA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(lof_results, hue = \"Anomaly\")"
      ],
      "metadata": {
        "id": "ORFwrVlry1P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(iforest,'IForest_Model')"
      ],
      "metadata": {
        "id": "raH2iht-y6Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Natural Language Processing**"
      ],
      "metadata": {
        "id": "aIZ9Fd06kn-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Several techniques are used to analyze text data among which Topic Modeling is a popular one. A topic model is a type of statistical model for discovering the abstract topics in a collection of documents. Topic modeling is a frequently used text-mining tool for the discovery of hidden semantic structures in a text data[13]"
      ],
      "metadata": {
        "id": "bPcGou14lBzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Datasets/NLP/kiva.csv\")"
      ],
      "metadata": {
        "id": "cci_zG_RlKO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.nlp import *\n",
        "dataset = get_topics(data = dataset, text = 'en')"
      ],
      "metadata": {
        "id": "C1FIrGvvlZ5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "JI2oANfmmKrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‘en’ is the name of the column containing text in the table ‘kiva’."
      ],
      "metadata": {
        "id": "bWNPFF6blk6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the code is executed, new columns with weight of topics and dominant topic are attached to the original table. There are many ways to visualize the output of Topic Mod"
      ],
      "metadata": {
        "id": "9oNhK9SzlvFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, PyCaret trains a Latent Dirichlet Allocation model with 4 topics. Default values can be changed easily:\n",
        "\n",
        "To change the number of topics you can use the num_topics parameter within get_topics( ) function.\n",
        "To change model type use the model parameter within the get_topics( ).\n",
        "See the example code for training a Non-Negative Matrix Factorization Model with 10 topics:[13]"
      ],
      "metadata": {
        "id": "gxhTa3N6mB19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.nlp import *\n",
        "dataset = get_topics(dataset, 'en', model = 'nmf', num_topics = 10)"
      ],
      "metadata": {
        "id": "52kZtJwTmBBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "96kDmtBom2wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyCaret has following ready-to-use algorithms for topic modeling:\n",
        "\n"
      ],
      "metadata": {
        "id": "Eo_TFKLhma1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](\n",
        "https://drive.google.com/uc?export=view&id=1zKKxIIy1O8ZGDeg01ZuEitf8KRXNTag4)"
      ],
      "metadata": {
        "id": "MDV9kcX4nZOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Association Rule Mining**"
      ],
      "metadata": {
        "id": "psATXe5xoLNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Association Rule Mining is a rule-based machine learning technique for discovering interesting relations between variables in a database. It is intended to identify strong rules using measures of interestingness. Some common business use cases for association rule mining are:\n",
        "\n",
        "✔ Market Basket Analysis to understand items frequently bought together.\n",
        "\n",
        "✔ Medical Diagnosis to assist physicians in determining occurrence probability of illness given factors and symptoms.\n",
        "[13]"
      ],
      "metadata": {
        "id": "07e_74u1oSyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Datasets/Association Rule Mining/france.csv\")"
      ],
      "metadata": {
        "id": "JDmMr3kmotbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apriori Algorithm**"
      ],
      "metadata": {
        "id": "KxY5UmxQpSwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.arules import *\n",
        "dataset = get_rules(dataset, transaction_id = 'InvoiceNo', item_id = 'Description')"
      ],
      "metadata": {
        "id": "h5cPWG5tpgVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "yyJH4AI7pjQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Time Series**"
      ],
      "metadata": {
        "id": "8-LZFroEyc2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset**"
      ],
      "metadata": {
        "id": "EAXf6jvMymAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "!pip install pycaret-ts-alpha"
      ],
      "metadata": {
        "id": "e9yDbquo0niD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from pycaret.internal.pycaret_experiment import TimeSeriesExperiment\n",
        "from sktime.utils.plotting import plot_series"
      ],
      "metadata": {
        "id": "4mI7D_Mu1FZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.datasets import get_data"
      ],
      "metadata": {
        "id": "QR45Af9Iyq-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_datasets = get_data()"
      ],
      "metadata": {
        "id": "XdHYKmnty_jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.datasets import get_data\n",
        "data=get_data('airline')\n"
      ],
      "metadata": {
        "id": "Qi-D8uj4yxuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMe-AMlnitQ8"
      },
      "source": [
        "# **AutoML-Gs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlijuc-di5QR"
      },
      "source": [
        "**Installing required libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwpdRorQi8WK"
      },
      "source": [
        "!pip install automl-gs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJJzKmNFjGTX"
      },
      "source": [
        "**Importing required libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZCsXFHljIkj"
      },
      "source": [
        "import automl_gs\n",
        "from automl_gs import automl_grid_search\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvMRJnLQjSTg"
      },
      "source": [
        "**Creating the Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfzVTAMRjeOn"
      },
      "source": [
        "automl_grid_search(MiceImputed, 'RESULT_TEXT')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz8BPvW3P8Hx"
      },
      "source": [
        "# **MLflow**[8]\n",
        "\n",
        "MLflow provides a convenient way to build end-to-end Machine Learning pipelines in production and in this guide\n",
        "\n",
        "MLflow is an open-source platform for managing the end-to-end machine learning lifecycle or pipeline. It supports multiple Machine Learning libraries, algorithms, deployment tools, and programming languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8cWDBKtQ-ep"
      },
      "source": [
        "The platform was created by Databricks has over 10,000 stars on GitHub with over 300+ contributors updating the platform on a daily basis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QC66c-SRDqi"
      },
      "source": [
        "The MLflow platform provides four major components:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q15NbkkNRFYi"
      },
      "source": [
        "- **MLflow Tracking** — This component is perfect for users looking to select the right hyper-parameters for their model as well as for recording model performance over time. You can record and query model experiments which include your code, data, config, and results.\n",
        "- **MLflow Projects** — This component is mostly used when trying to reproduce your Machine Learning project on a different machine (similar to Docker images and containers). You can package your data science code in a given format to reproduce model runs on any platform.\n",
        "- **MLflow Models** — This component is for you if you are looking to deploy Machine Learning models in the real world. With this component, you can deploy machine learning models in diverse serving environments.\n",
        "- **MLflow Model Registry**— This component is great for you if you are looking to manage multiple Machine Learning models. Using this component, you can store, annotate, discover, and manage Machine Learning models in a central repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXa4xmVSSGsv"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1BoZqaCplUEEJ8fDpk3k167WGi_GmJI_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJYWowyzSSXf"
      },
      "source": [
        "- Individual Data Scientists can use MLflow to track experiments locally, organize code in projects for future reuse, and deploy models using MLflow’s deployment tools.\n",
        "- Large Organizations can share projects, models, and results with any teams using MLflow.\n",
        "- Data Science Teams can log metrics and compare results across multiple users working on the same problem\n",
        "- Production Engineers can deploy models from diverse ML libraries, store the models as files in a management system, and track which run a model came from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEVSTGhmSg8r"
      },
      "source": [
        "Based on these components, MLflow is designed to be useful for an individual to a large range of people working as a team. Some of its applications are as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzmmT8ZKStGt"
      },
      "source": [
        "If you’re still undecided about learning how to use the platform, you can go over the MLflow components again and figure out if the platform is for you or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NllAK6hmUAUH"
      },
      "source": [
        "**Installing MLflow to use with Python**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKriiariUFCc"
      },
      "source": [
        "**Using with Python [4]**\n",
        "\n",
        "Remember we passed log_experiment = True in the setup function along with experiment_name = 'diamond' . Let’s see the magic PyCaret has done with the help of MLflow behind the scene. To see the magic let’s initiate the MLflow server:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jiwt9i9LUXCH"
      },
      "source": [
        "# within notebook (notice ! sign infront)\n",
        "!mlflow ui\n",
        "# on command line in the same folder\n",
        "#mlflow ui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvzazsunYIof"
      },
      "source": [
        "!mlflow ui --host 0.0.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSyTRCPjUahe"
      },
      "source": [
        "Now open your browser and type “localhost:5000”. It will open a UI like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rofMGBlUuWl"
      },
      "source": [
        "Remember that MLflow supports multiple programming languages and tools such as R-programming language or Python. It also comes with a graphical user interface that you can access from your browser once you successfully install MLflow.[8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaMK4Ca5U06l"
      },
      "source": [
        "To keep this guide concise and easy to digest, we’ll show you how you can install MLflow to use with Python. To install MLflow, open up your command line/terminal and write the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMQfIK-RU2hl"
      },
      "source": [
        "!pip install mlflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5ScuZwPVIAO"
      },
      "source": [
        "Note: You must have Python installed in your system to use pip which is Python’s package manager."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWq_TXcoVMrF"
      },
      "source": [
        "Once you execute the command, MLflow will get installed in your system. You can check if the installation is successful or not by importing MLflow in Python using the following line of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcgo8jZiVQ_l"
      },
      "source": [
        "import mlflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml198OF5Vbju"
      },
      "source": [
        "If this line of Python code doesn’t give you an error, then, you’ve successfully installed MLflow to use with Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utD3ulx-VfVc"
      },
      "source": [
        "**Component 1: MLflow Tracking**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdrXTWuAZbtV"
      },
      "source": [
        "# Importing the os library to work with operating system functionalities\n",
        "import os\n",
        "\n",
        "# Importing tracking functions from MLflow\n",
        "from mlflow import log_metric, log_param, log_artifacts\n",
        "\n",
        "# Logging a parameter (key-value pair)\n",
        "log_param(\"param1\", 0)\n",
        "\n",
        "# Logging a metric; metrics can be updated throughout the run\n",
        "log_metric(\"foo\", 100)\n",
        "log_metric(\"foo\", 200)\n",
        "log_metric(\"foo\", 300)\n",
        "\n",
        "# Create a file called test.text in outputs directory\n",
        "if not os.path.exists(\"outputs\"):\n",
        "    os.makedirs(\"outputs\")\n",
        "with open(\"outputs/test.txt\", \"w\") as f:\n",
        "    f.write(\"hello world!\")\n",
        "\n",
        "# Logging an artifact (output file)\n",
        "log_artifacts(\"outputs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZBaq1dGZgFZ"
      },
      "source": [
        "!mlflow ui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AutoML**[9]"
      ],
      "metadata": {
        "id": "oLv0-wNq1s7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An AutoML pipeline includes data preprocessing, feature engineering, feature selection, model training, hyperparameter tuning, and algorithm selection"
      ],
      "metadata": {
        "id": "M47_UJN44vVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if there was an open-source Python package that could do all of the above and automatically determine the best model? A package that would explain to you exactly how each ML model is built & also provide you with a detailed report!\n",
        "The answer to the question is the Python package ‘mjlar supervised’. It was developed by MJLAR with the goal of helping software developers and data analysts that do not have classical ML training."
      ],
      "metadata": {
        "id": "IH1AGUwd43_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The package ‘mjlar supervised’allows you to select machine learning algorithms, preprocess dataset, train & tune the model, and finally explain and evaluate the model."
      ],
      "metadata": {
        "id": "tC1OBZWT5Azz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea behind AutoML is to continuously build and test machine learning models using a neural network. As a new set of data is added, the neural network will automatically determine whether it needs to create a new specialized model by training and executing its own algorithm or simply improve an existing one. Essentially, AutoML creates sophisticated machine learning programs that can be accessed via APIs where the output is returned in the form of API calls.\n",
        "AutoML is clearly a very powerful tool for automating much of this process using machine learning algorithms. But you’re still going to need programmers to define heuristics for machines or identify how they should make decisions and also learn about various data science concepts.[10]"
      ],
      "metadata": {
        "id": "vBmvXFF2AV5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why AutoML?**"
      ],
      "metadata": {
        "id": "RBeDpR9IApqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoML would continuously build models based on new data sets provided by an enterprise and improve them when better ones are discovered by the AutoML algorithm. The idea of applying neural networks to this process is not new — it’s been around for a long time and several companies have experimented with it in their own ways. AutoML has tremendous implications for non-technical people who want to leverage insights from data, but don’t have the programming chops or the resources to implement ML solutions. All they need now is an API call where they can get data back in the form of “recommendations”, such as which products are ideal for each customer based on his purchasing history, demographics, and other aspects. The other possibility is that they will get an alert if a certain event happens and the solution to prevent it.[10]"
      ],
      "metadata": {
        "id": "Di9HmVU4AsyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What Does AutoML Do?**[10]\n"
      ],
      "metadata": {
        "id": "t_TDvqdSA0CC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoML can be used for solving three primary problems: Model Building, Hyperparameter Tuning & Selection, and Model Optimization.\n",
        "Model Building — This refers to setting up the model based on parameters in your data set (such as predicting the probability of customers churning) so that machine learning algorithms can compare them with labels (actual instances) and then feedback their “correctness” or explain how inaccurate they are. Once modeled, results can be analyzed using tools like TensorBoard. The process of refining these models is known as Hyperparameter tuning & selection — this refers to setting up the appropriate parameters in a model so that it learns data efficiently. When you’re using AutoML, this is done by providing an algorithm with lots of examples and letting it come up with its own metrics for measuring what makes sense. For example, if you want a model that recognizes images — you’ll need to provide it with hundreds of thousands of images so it can identify patterns between them. Model Optimization refers to improving your existing models after training them on large datasets provided by an enterprise; AutoML helps optimize your models based on computation speed and accuracy.\n",
        "AutoML has two powerful components — Abalone and Ranker (which have been open-sourced).\n",
        "Abalone: This component takes care of creating a simple model of your data set, by using AutoML’s cloud platform that uses Tensorflow. It also helps you to build more advanced models with the help of human experts in machine learning.\n",
        "Ranker: This component recommends which models (created via Abalone) are the best for a particular enterprise based on their usage requirements and results."
      ],
      "metadata": {
        "id": "_7rgwwFsA5OJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithm Selection**[9]"
      ],
      "metadata": {
        "id": "gxnNxyQx-Ai-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This package allows the user to check their model with various algorithms: Baseline, Linear, Random Forest, Extra Trees, LightGBM, Xgboost, CatBoost, Neural Networks, Ensemble, and Nearest Neighbors. Once you run the code, the output will show you how much time each model took to train the dataset and the root mean squared error of the trained model. The package will select the algorithm with the lowest root mean squared error."
      ],
      "metadata": {
        "id": "m8JpFjNa-Cvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Available Modes**[9]\n",
        "\n",
        "The available modes allow the user to explain and optimize the ML model according to the audience. It has four modes — Explain, Perform, Compete and Optuna."
      ],
      "metadata": {
        "id": "wvIqOBI8-IeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl = AutoML(mode=”Explain”)"
      ],
      "metadata": {
        "id": "hhFo7stm-aJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Explain mode allows the user to explain the model including making learning curves, feature plots, and SHAP plots."
      ],
      "metadata": {
        "id": "yovifnr4-VuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl = AutoML(mode=”Perform”)\n"
      ],
      "metadata": {
        "id": "bCVROikv-cXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Perform mode allows the user to train a model that will be used in real-life use cases."
      ],
      "metadata": {
        "id": "2TNinMbH-luU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl = AutoML(mode=”Compete”)"
      ],
      "metadata": {
        "id": "LIwp9nIl-syk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Compete mode will allow the user to adapt a validation strategy depending on the size of the dataset and can be used for entering into machine learning competitions."
      ],
      "metadata": {
        "id": "093rG7oN-wmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl = AutoML(mode=”Optuna”)\n"
      ],
      "metadata": {
        "id": "_VtvlDJr--C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Optuna mode should be used when the priority is the performance of the model instead of time."
      ],
      "metadata": {
        "id": "TAw42Tzz_EgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mljar-supervised\n"
      ],
      "metadata": {
        "id": "77kJpRoK2mp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=Train_data\n"
      ],
      "metadata": {
        "id": "gOXDgk4F59Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['gender'] = data['gender'].fillna(data['gender'].mode()[0])\n",
        "data['ssc_b'] = data['ssc_b'].fillna(data['ssc_b'].mode()[0])\n",
        "data['hsc_b'] = data['hsc_b'].fillna(data['hsc_b'].mode()[0])\n",
        "data['hsc_s'] = data['hsc_s'].fillna(data['hsc_s'].mode()[0])\n",
        "data['degree_t'] = data['degree_t'].fillna(data['degree_t'].mode()[0])\n",
        "data['workex'] = data['workex'].fillna(data['workex'].mode()[0])\n",
        "data['specialisation'] = data['specialisation'].fillna(data['specialisation'].mode()[0])\n",
        "data['status'] = data['status'].fillna(data['status'].mode()[0])"
      ],
      "metadata": {
        "id": "tg_SRR6z4aH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical features to continuous features with Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lencoders = {}\n",
        "for col in data.select_dtypes(include=['object']).columns:\n",
        "    lencoders[col] = LabelEncoder()\n",
        "    data[col] = lencoders[col].fit_transform(data[col])"
      ],
      "metadata": {
        "id": "s4AiZ8KF6HC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=data.drop('specialisation',axis=1)\n"
      ],
      "metadata": {
        "id": "nxHrMYRg6Nmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=data[['specialisation']]\n"
      ],
      "metadata": {
        "id": "sN-xP3Mq6TRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=100)"
      ],
      "metadata": {
        "id": "SkGM-w5V6dPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "!pip install scikit-learn==0.24"
      ],
      "metadata": {
        "id": "w94F0cMx77VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from supervised.automl import AutoML\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "lmXH4S1k288e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "automl = AutoML()\n",
        "automl.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Xs0g9q4o8Mv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = automl.predict_all(X_test)\n",
        "print(predictions.head())\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, predictions[\"label\"].astype(int)))"
      ],
      "metadata": {
        "id": "NhhRUuYY80Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "automl = AutoML(mode=\"Perform\")\n",
        "automl.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fB-AVcvW9KcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the accuracy on test data\n",
        "predictions = automl.predict_all(X_test)\n",
        "print(predictions.head())\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, predictions[\"label\"].astype(int)))"
      ],
      "metadata": {
        "id": "l9Ypog-w9kap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install autokeras\n"
      ],
      "metadata": {
        "id": "KKokCjLTDINa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autokeras import StructuredDataClassifier"
      ],
      "metadata": {
        "id": "CbsbsjnEFRvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = StructuredDataClassifier(max_trials = 20)\n"
      ],
      "metadata": {
        "id": "Tgx_0ex2FzPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.fit(x=X_train, y=y_train)\n"
      ],
      "metadata": {
        "id": "iJg2GSchGAeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = search.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy is {}'.format(acc))"
      ],
      "metadata": {
        "id": "cEFLDUE6GNxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = search.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy is {}'.format(acc))"
      ],
      "metadata": {
        "id": "otLKcCn-GSsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLBox**"
      ],
      "metadata": {
        "id": "EKVHEHumRF45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Machine Learning model is not a difficult task because Python provides ample libraries which can help in creating models related to problems like Regression, Classification, etc. Python packages like Sklearn Statsmodel can be used for creating these models but the difficult part is optimizing and generalizing these models so that they work on unseen data also **[16]**.In other words, creating a Machine Learning model alone does not solve the problem, we should also be able to tune the hyperparameter of these models to make it generalized and achieve higher performance and accuracy. There are a large number of Machine Learning models from which we can select a model which works best for our dataset, but it is a time-consuming process because we need to write the code and train the model for every algorithm. Similarly, if we are able to select a model then we need to select the best hyperparameter of the model which again is a time-consuming process **[16]**."
      ],
      "metadata": {
        "id": "c0MfiFTaRLJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, in order to bring down the efforts and time taken in these processes, we can automate it using **MLBox**. It is an open-source python library that is used for automating the Machine Learning process which includes feature selection, Hyperparameter Optimization, Creating the model, and generating predictions using that model **[16]**"
      ],
      "metadata": {
        "id": "ggpqtGv6Rrn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing required libraries**\n"
      ],
      "metadata": {
        "id": "iRYpzbGBRzgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlbox"
      ],
      "metadata": {
        "id": "fVNvxwbuR3BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing required libraries**"
      ],
      "metadata": {
        "id": "9LBjYBw4SEkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlbox.preprocessing import *\n",
        "from mlbox.optimisation import *\n",
        "from mlbox.prediction import*"
      ],
      "metadata": {
        "id": "JmirXZ3ESOrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading dataset**"
      ],
      "metadata": {
        "id": "YNk_ozY4TBMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "Train_data = pd.read_csv(\"/content/drive/MyDrive/Datasets/Student field Recommendation /Placement_Data_Full_Class.csv\")"
      ],
      "metadata": {
        "id": "-_CUwS-UUPPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [\"/content/drive/MyDrive/Datasets/Student field Recommendation /Train.csv\",\"/content/drive/MyDrive/Datasets/Student field Recommendation /Test.csv\"]\n",
        "target_name = \"specialisation\""
      ],
      "metadata": {
        "id": "90ZZFwwyTIMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd = Reader(sep = \",\")\n",
        "df = rd.train_test_split(paths, target_name)"
      ],
      "metadata": {
        "id": "SUJdmgUoTML1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Models**"
      ],
      "metadata": {
        "id": "SFmiEq4rdGNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining Optimiser\n",
        "opt = Optimiser(scoring = \"accuracy\", n_folds = 5)\n",
        "#Defining the model\n",
        "space = {\n",
        "'est__strategy':{\"search\":\"choice\",\n",
        "\"space\":[\"LightGBM\"]},\n",
        "'est__n_estimators':{\"search\":\"choice\",\n",
        "\"space\":[150]},\n",
        "'est__colsample_bytree':{\"search\":\"uniform\",\n",
        "\"space\":[0.8,0.95]},\n",
        "'est__subsample':{\"search\":\"uniform\",\n",
        "\"space\":[0.8,0.95]},\n",
        "'est__max_depth':{\"search\":\"choice\",\n",
        "\"space\":[5,6,7,8,9]},\n",
        "'est__learning_rate':{\"search\":\"choice\",\n",
        "\"space\":[0.07]}\n",
        "}\n",
        "params = opt.optimise(space, df,15)"
      ],
      "metadata": {
        "id": "yrCeMPNocERL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Importance**\n"
      ],
      "metadata": {
        "id": "82u9Ugi3dNt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prd = Predictor()\n",
        "prd.fit_predict(params, df)"
      ],
      "metadata": {
        "id": "nS4Fh-YGcMfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF7dADqbc8c4"
      },
      "source": [
        "# **References**\n",
        "\n",
        "[1-Build a machine learning model with PyCaret and corresponding user interface with Gradio](https://medium.com/nerd-for-tech/build-a-machine-learning-model-with-pycaret-and-corresponding-user-interface-with-gradio-57ff09b7d262)\n",
        "\n",
        "[2-PyCaret in Machine Learning](https://thecleverprogrammer.com/2021/03/07/pycaret-in-machine-learning/)\n",
        "\n",
        "[3-PyCaret 101: An introduction for beginners](https://www.kdnuggets.com/2021/06/pycaret-101-introduction-beginners.html?fbclid=IwAR29t4C5QplspexoIyAd4eYfUjlZSOFL5wVmxc9sU5qXr_mMqIPfaJVmP6Y)\n",
        "\n",
        "[4-Easy MLOps with PyCaret + MLflow](https://towardsdatascience.com/easy-mlops-with-pycaret-mlflow-7fbcbf1e38c6)\n",
        "\n",
        "[5-Binary Classification Tutorial Level Beginner](https://colab.research.google.com/drive/1GqQ3XAIzg4krBbnOpKyeRqT0qBQhdwYL#scrollTo=GM-nQ7LqEQma)\n",
        "\n",
        "[6-Create Clusters](https://pycaret.org/create-clusters/)\n",
        "\n",
        "[7-Plot Model](https://pycaret.org/plot-model/)\n",
        "\n",
        "[8-MLflow For Machine Learning Pipelines [Ultimate Guide]](https://medium.com/@theclickreader/mlflow-for-machine-learning-pipelines-ultimate-guide-821e55370034)\n",
        "\n",
        "[9-Gentle Introduction to New AutoML Package by MJLAR!](https://medium.com/mlearning-ai/gentle-introduction-to-new-automl-package-by-mjlar-bc51a99ba53c)\n",
        "\n",
        "[10-AutoML: The future of Data Science and Machine Learning](https://protonautoml.medium.com/automl-the-future-of-data-science-and-machine-learning-45abb8f5ebcf)\n",
        "\n",
        "[11- Predicting Machine Maintenance using Machine Learning](https://medium.com/analytics-vidhya/predicting-machine-maintenance-using-machine-learning-ee694c7fa0f0)\n",
        "\n",
        "\n",
        "[12- 7 Top AutoML Tools](https://victorzhou.com/posts/tools-for-auto-ml/)\n",
        "\n",
        "[13-Machine Learning in Power BI using PyCaret](https://www.kdnuggets.com/2020/05/machine-learning-power-bi-pycaret.html)\n",
        "\n",
        "[14- Getting familiar with PyCaret for anomaly detection](https://www.analyticsvidhya.com/blog/2021/05/getting-familiar-with-pycaret-for-anomaly-detection/)\n",
        "\n",
        "[15- Introduction to Clustering in Python with PyCaret](https://towardsdatascience.com/introduction-to-clustering-in-python-with-pycaret-5d869b9714a3)\n",
        "\n",
        "[16-Automating Machine Learning Modelling](https://towardsdatascience.com/automating-machine-learning-modelling-62aac2081e3f)\n",
        "\n",
        "\n",
        "[Introduction to Anomaly Detection in Python with PyCaret](https://towardsdatascience.com/introduction-to-anomaly-detection-in-python-with-pycaret-2fecd7144f87)\n",
        "\n",
        "[How to Use pyGAM to Fit More Flexible Functions to Your Data](https://tech-at-kraftheinz.medium.com/how-to-use-pygam-to-fit-more-flexible-functions-to-your-data-5de16e7d913a)\n",
        "\n",
        "[Automating Machine Learning Modelling](https://towardsdatascience.com/automating-machine-learning-modelling-62aac2081e3f)\n",
        "\n",
        "[What Are Baseline Models and Benchmarking For Machine Learning, Why We Need Them? Part 1 Classification](https://pub.towardsai.net/what-are-baseline-models-and-benchmarking-for-machine-learning-why-we-need-them-affe0714cd07)\n",
        "\n",
        "\n",
        "[Time Series](https://pycaret.readthedocs.io/en/time_series/api/time_series.html)\n"
      ]
    }
  ]
}